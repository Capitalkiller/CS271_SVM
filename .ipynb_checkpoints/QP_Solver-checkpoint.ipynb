{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from sklearn import svm\n",
    "from lib import *\n",
    "from svm import *\n",
    "from QPslover import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:  (432L, 16L)\n",
      "train lable:  (432L,)\n",
      "validation data:  (49L, 16L)\n",
      "validation lable:  (49L,)\n"
     ]
    }
   ],
   "source": [
    "data, lable  = load_train(\"./data/0vs8Source.csv\")\n",
    "train_data, train_lable, validation_data, validation_lable = shuffleData(data, lable)\n",
    "print \"train data: \", train_data.shape\n",
    "print \"train lable: \", train_lable.shape\n",
    "print \"validation data: \", validation_data.shape\n",
    "print \"validation lable: \", validation_lable.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:  (481L, 16L)\n",
      "train lable:  (481L,)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_lable =  load_train(\"./data/0vs8Source.csv\")\n",
    "print \"train data: \", train_data.shape\n",
    "print \"train lable: \", train_lable.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:  (36L, 16L)\n",
      "train lable:  (36L,)\n",
      "validation data:  (3L, 16L)\n",
      "validation lable:  (3L,)\n"
     ]
    }
   ],
   "source": [
    "target_data, target_lable  = load_train(\"./data/0vs8Target.csv\")\n",
    "target_data, target_lable, target_v_data, target_v_lable = shuffleData(target_data, target_lable)\n",
    "print \"train data: \", target_data.shape\n",
    "print \"train lable: \", target_lable.shape\n",
    "print \"validation data: \", target_v_data.shape\n",
    "print \"validation lable: \", target_v_lable.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:  (39L, 16L)\n",
      "train lable:  (39L,)\n"
     ]
    }
   ],
   "source": [
    "target_data, target_lable  = load_train(\"./data/0vs8Target.csv\")\n",
    "print \"train data: \", target_data.shape\n",
    "print \"train lable: \", target_lable.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# it is 0 vs 8 problem, so divde only two class\n",
    "train_lable[train_lable <= 4 ] = -1\n",
    "train_lable[train_lable > 4] = 1\n",
    "validation_lable[validation_lable <= 4 ] = -1\n",
    "validation_lable[validation_lable > 4] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_lable[target_lable <= 4 ] = -1\n",
    "target_lable[target_lable > 4] = 1\n",
    "target_v_lable[target_v_lable <= 4 ] = -1\n",
    "target_v_lable[target_v_lable > 4] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.146936325917\n",
      "            Iterations: 7\n",
      "            Function evaluations: 134\n",
      "            Gradient evaluations: 7\n"
     ]
    }
   ],
   "source": [
    "w, b = QP_Slover(train_data, train_lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8974358974358975"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_vali = prediction_QP(w, b, target_data)\n",
    "correct_rate_only(pre_vali, target_lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.029366535253\n",
      "            Iterations: 29\n",
      "            Function evaluations: 567\n",
      "            Gradient evaluations: 29\n"
     ]
    }
   ],
   "source": [
    "w_target, b_target = QP_Slover_transfer(target_data, target_lable, w, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_vali = prediction_QP(w_target, b_target, target_data)\n",
    "correct_rate_only(pre_vali, target_lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200L, 16L)\n",
      "train data:  (200L, 16L)\n"
     ]
    }
   ],
   "source": [
    "test_data  = load_test(\"./data/0vs8TestNoLabels.csv\")\n",
    "print \"train data: \", test_data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_test = prediction_QP(w_target, b_target, test_data)\n",
    "test_lable = np.zeros(200)\n",
    "test_lable[:100] = 1\n",
    "test_lable[100:] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.905"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_rate_only(pre_test, test_lable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661455858\n",
      "            Iterations: 27\n",
      "            Function evaluations: 529\n",
      "            Gradient evaluations: 27\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293662890518\n",
      "            Iterations: 26\n",
      "            Function evaluations: 511\n",
      "            Gradient evaluations: 26\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293664958138\n",
      "            Iterations: 31\n",
      "            Function evaluations: 604\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.029366123748\n",
      "            Iterations: 30\n",
      "            Function evaluations: 588\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293663354308\n",
      "            Iterations: 29\n",
      "            Function evaluations: 567\n",
      "            Gradient evaluations: 29\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293665841553\n",
      "            Iterations: 29\n",
      "            Function evaluations: 566\n",
      "            Gradient evaluations: 29\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293660997895\n",
      "            Iterations: 30\n",
      "            Function evaluations: 586\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293662264675\n",
      "            Iterations: 28\n",
      "            Function evaluations: 547\n",
      "            Gradient evaluations: 28\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661168633\n",
      "            Iterations: 30\n",
      "            Function evaluations: 586\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.029366114294\n",
      "            Iterations: 29\n",
      "            Function evaluations: 566\n",
      "            Gradient evaluations: 29\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661061634\n",
      "            Iterations: 30\n",
      "            Function evaluations: 587\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661587976\n",
      "            Iterations: 32\n",
      "            Function evaluations: 625\n",
      "            Gradient evaluations: 32\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661988197\n",
      "            Iterations: 25\n",
      "            Function evaluations: 490\n",
      "            Gradient evaluations: 25\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293663037012\n",
      "            Iterations: 26\n",
      "            Function evaluations: 510\n",
      "            Gradient evaluations: 26\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293660981104\n",
      "            Iterations: 29\n",
      "            Function evaluations: 567\n",
      "            Gradient evaluations: 29\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293662420567\n",
      "            Iterations: 29\n",
      "            Function evaluations: 566\n",
      "            Gradient evaluations: 29\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661533426\n",
      "            Iterations: 30\n",
      "            Function evaluations: 586\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.029366302057\n",
      "            Iterations: 29\n",
      "            Function evaluations: 566\n",
      "            Gradient evaluations: 29\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661403837\n",
      "            Iterations: 30\n",
      "            Function evaluations: 585\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661230913\n",
      "            Iterations: 30\n",
      "            Function evaluations: 585\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.029366096417\n",
      "            Iterations: 31\n",
      "            Function evaluations: 604\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661311111\n",
      "            Iterations: 28\n",
      "            Function evaluations: 549\n",
      "            Gradient evaluations: 28\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661657643\n",
      "            Iterations: 31\n",
      "            Function evaluations: 606\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661083858\n",
      "            Iterations: 31\n",
      "            Function evaluations: 605\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661170059\n",
      "            Iterations: 31\n",
      "            Function evaluations: 606\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661543678\n",
      "            Iterations: 28\n",
      "            Function evaluations: 548\n",
      "            Gradient evaluations: 28\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661801566\n",
      "            Iterations: 31\n",
      "            Function evaluations: 605\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293660896087\n",
      "            Iterations: 28\n",
      "            Function evaluations: 548\n",
      "            Gradient evaluations: 28\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.029366496798\n",
      "            Iterations: 26\n",
      "            Function evaluations: 510\n",
      "            Gradient evaluations: 26\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.02936635302\n",
      "            Iterations: 30\n",
      "            Function evaluations: 586\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661649026\n",
      "            Iterations: 31\n",
      "            Function evaluations: 605\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293663175342\n",
      "            Iterations: 30\n",
      "            Function evaluations: 585\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293660921109\n",
      "            Iterations: 29\n",
      "            Function evaluations: 568\n",
      "            Gradient evaluations: 29\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661645712\n",
      "            Iterations: 30\n",
      "            Function evaluations: 585\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661839077\n",
      "            Iterations: 27\n",
      "            Function evaluations: 529\n",
      "            Gradient evaluations: 27\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0309119124289\n",
      "            Iterations: 16\n",
      "            Function evaluations: 320\n",
      "            Gradient evaluations: 16\n",
      "0.91\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.029366205872\n",
      "            Iterations: 31\n",
      "            Function evaluations: 604\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0300131376323\n",
      "            Iterations: 16\n",
      "            Function evaluations: 319\n",
      "            Gradient evaluations: 16\n",
      "0.91\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293664954334\n",
      "            Iterations: 32\n",
      "            Function evaluations: 624\n",
      "            Gradient evaluations: 32\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293664738069\n",
      "            Iterations: 31\n",
      "            Function evaluations: 604\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0305232846073\n",
      "            Iterations: 20\n",
      "            Function evaluations: 395\n",
      "            Gradient evaluations: 20\n",
      "0.91\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293662483719\n",
      "            Iterations: 32\n",
      "            Function evaluations: 624\n",
      "            Gradient evaluations: 32\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661346582\n",
      "            Iterations: 32\n",
      "            Function evaluations: 624\n",
      "            Gradient evaluations: 32\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661065102\n",
      "            Iterations: 30\n",
      "            Function evaluations: 587\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293665063114\n",
      "            Iterations: 30\n",
      "            Function evaluations: 585\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293664950463\n",
      "            Iterations: 28\n",
      "            Function evaluations: 549\n",
      "            Gradient evaluations: 28\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293663339002\n",
      "            Iterations: 28\n",
      "            Function evaluations: 549\n",
      "            Gradient evaluations: 28\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293662090316\n",
      "            Iterations: 29\n",
      "            Function evaluations: 567\n",
      "            Gradient evaluations: 29\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661524426\n",
      "            Iterations: 33\n",
      "            Function evaluations: 642\n",
      "            Gradient evaluations: 33\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0308872358137\n",
      "            Iterations: 18\n",
      "            Function evaluations: 359\n",
      "            Gradient evaluations: 18\n",
      "0.91\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661671578\n",
      "            Iterations: 27\n",
      "            Function evaluations: 528\n",
      "            Gradient evaluations: 27\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293660952805\n",
      "            Iterations: 26\n",
      "            Function evaluations: 510\n",
      "            Gradient evaluations: 26\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.029366313601\n",
      "            Iterations: 30\n",
      "            Function evaluations: 586\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661281601\n",
      "            Iterations: 32\n",
      "            Function evaluations: 624\n",
      "            Gradient evaluations: 32\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.029366405392\n",
      "            Iterations: 30\n",
      "            Function evaluations: 586\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293662675929\n",
      "            Iterations: 31\n",
      "            Function evaluations: 606\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293660964017\n",
      "            Iterations: 31\n",
      "            Function evaluations: 605\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.029366168927\n",
      "            Iterations: 26\n",
      "            Function evaluations: 511\n",
      "            Gradient evaluations: 26\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661070161\n",
      "            Iterations: 30\n",
      "            Function evaluations: 586\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293663837967\n",
      "            Iterations: 31\n",
      "            Function evaluations: 605\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293663712093\n",
      "            Iterations: 29\n",
      "            Function evaluations: 567\n",
      "            Gradient evaluations: 29\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661981479\n",
      "            Iterations: 28\n",
      "            Function evaluations: 546\n",
      "            Gradient evaluations: 28\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661207411\n",
      "            Iterations: 31\n",
      "            Function evaluations: 605\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661012382\n",
      "            Iterations: 30\n",
      "            Function evaluations: 585\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.029366281613\n",
      "            Iterations: 29\n",
      "            Function evaluations: 567\n",
      "            Gradient evaluations: 29\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293663260822\n",
      "            Iterations: 30\n",
      "            Function evaluations: 584\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293662224868\n",
      "            Iterations: 31\n",
      "            Function evaluations: 606\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293664284715\n",
      "            Iterations: 30\n",
      "            Function evaluations: 586\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.029366272214\n",
      "            Iterations: 28\n",
      "            Function evaluations: 548\n",
      "            Gradient evaluations: 28\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293660930651\n",
      "            Iterations: 32\n",
      "            Function evaluations: 624\n",
      "            Gradient evaluations: 32\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293662968289\n",
      "            Iterations: 30\n",
      "            Function evaluations: 586\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661162491\n",
      "            Iterations: 30\n",
      "            Function evaluations: 586\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661234879\n",
      "            Iterations: 27\n",
      "            Function evaluations: 529\n",
      "            Gradient evaluations: 27\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661931218\n",
      "            Iterations: 27\n",
      "            Function evaluations: 531\n",
      "            Gradient evaluations: 27\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293660892055\n",
      "            Iterations: 25\n",
      "            Function evaluations: 491\n",
      "            Gradient evaluations: 25\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661658727\n",
      "            Iterations: 29\n",
      "            Function evaluations: 567\n",
      "            Gradient evaluations: 29\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293664439654\n",
      "            Iterations: 29\n",
      "            Function evaluations: 566\n",
      "            Gradient evaluations: 29\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661097228\n",
      "            Iterations: 30\n",
      "            Function evaluations: 586\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293660901993\n",
      "            Iterations: 28\n",
      "            Function evaluations: 548\n",
      "            Gradient evaluations: 28\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661375771\n",
      "            Iterations: 30\n",
      "            Function evaluations: 586\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661837082\n",
      "            Iterations: 29\n",
      "            Function evaluations: 566\n",
      "            Gradient evaluations: 29\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661086876\n",
      "            Iterations: 31\n",
      "            Function evaluations: 605\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0305094331958\n",
      "            Iterations: 13\n",
      "            Function evaluations: 261\n",
      "            Gradient evaluations: 13\n",
      "0.91\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661287933\n",
      "            Iterations: 30\n",
      "            Function evaluations: 586\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293664020133\n",
      "            Iterations: 30\n",
      "            Function evaluations: 587\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661998563\n",
      "            Iterations: 26\n",
      "            Function evaluations: 509\n",
      "            Gradient evaluations: 26\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0300741560722\n",
      "            Iterations: 18\n",
      "            Function evaluations: 358\n",
      "            Gradient evaluations: 18\n",
      "0.91\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.030632495965\n",
      "            Iterations: 18\n",
      "            Function evaluations: 359\n",
      "            Gradient evaluations: 18\n",
      "0.91\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.029366209207\n",
      "            Iterations: 30\n",
      "            Function evaluations: 587\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661673364\n",
      "            Iterations: 30\n",
      "            Function evaluations: 585\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.029366297298\n",
      "            Iterations: 30\n",
      "            Function evaluations: 586\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661568129\n",
      "            Iterations: 31\n",
      "            Function evaluations: 605\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293664111329\n",
      "            Iterations: 30\n",
      "            Function evaluations: 584\n",
      "            Gradient evaluations: 30\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0311633988741\n",
      "            Iterations: 17\n",
      "            Function evaluations: 340\n",
      "            Gradient evaluations: 17\n",
      "0.91\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661340712\n",
      "            Iterations: 27\n",
      "            Function evaluations: 531\n",
      "            Gradient evaluations: 27\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661053092\n",
      "            Iterations: 31\n",
      "            Function evaluations: 605\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293660966392\n",
      "            Iterations: 27\n",
      "            Function evaluations: 528\n",
      "            Gradient evaluations: 27\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293661168499\n",
      "            Iterations: 28\n",
      "            Function evaluations: 549\n",
      "            Gradient evaluations: 28\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0293663478701\n",
      "            Iterations: 31\n",
      "            Function evaluations: 604\n",
      "            Gradient evaluations: 31\n",
      "0.905\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0307307507817\n",
      "            Iterations: 15\n",
      "            Function evaluations: 299\n",
      "            Gradient evaluations: 15\n",
      "0.91\n",
      "best rate = 0.91, best k = 3500000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh0AAAF2CAYAAADKuyrjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npRXX4iMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa42c550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trace_k =[]\n",
    "trace_rate =[]\n",
    "best = 0\n",
    "best_k = 0\n",
    "for i in range(100):\n",
    "    k = 100000*i\n",
    "    w_target, b_target = QP_Slover_transfer(target_data, target_lable, w, k)\n",
    "    pre_test = prediction_QP(w_target, b_target, test_data)\n",
    "    rate = correct_rate_only(pre_test, test_lable)\n",
    "    trace_rate.append(rate)\n",
    "    trace_k.append(k)\n",
    "    if best < rate:\n",
    "        best = rate\n",
    "        best_k = k\n",
    "    print rate\n",
    "plt.plot(trace_k, trace_rate)    \n",
    "print \"best rate = %r, best k = %i\" %(best, best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
